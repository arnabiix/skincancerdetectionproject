{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "train_path = 'C:/Users/Pratik/OneDrive/Desktop/pr_project/base_dir/train_dir'\n",
    "val_path = 'C:/Users/Pratik/OneDrive/Desktop/pr_project/base_dir/val_dir'\n",
    "\n",
    "\n",
    "# Initialize lists for train data\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# Cap number of images per label\n",
    "max_images_per_label = 4410\n",
    "\n",
    "# Process training directory\n",
    "for label in os.listdir(train_path):\n",
    "    label_count = 0\n",
    "    for image in os.listdir(os.path.join(train_path, label)):\n",
    "        if label_count >= max_images_per_label:\n",
    "            break\n",
    "        filepath = os.path.join(train_path, label, image)\n",
    "        train_images.append(filepath)\n",
    "        train_labels.append(label)\n",
    "        label_count += 1\n",
    "\n",
    "# Convert training data to DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    'Images': train_images,\n",
    "    'Labels': train_labels\n",
    "})\n",
    "\n",
    "# Initialize lists for validation data\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "# Process validation directory\n",
    "for label in os.listdir(val_path):\n",
    "    for image in os.listdir(os.path.join(val_path, label)):\n",
    "        filepath = os.path.join(val_path, label, image)\n",
    "        val_images.append(filepath)\n",
    "        val_labels.append(label)\n",
    "\n",
    "# Convert validation data to DataFrame\n",
    "val_df = pd.DataFrame({\n",
    "    'Images': val_images,\n",
    "    'Labels': val_labels\n",
    "})\n",
    "\n",
    "# Display DataFrame information\n",
    "print(\"Training Data\")\n",
    "print(train_df.head())\n",
    "print(train_df['Labels'].value_counts())\n",
    "\n",
    "print(\"\\nValidation Data\")\n",
    "print(val_df.head())\n",
    "print(val_df['Labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "                                                  Images Labels\n",
      "26808  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...   vasc\n",
      "29600  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...   vasc\n",
      "18900  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...    mel\n",
      "26653  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...   vasc\n",
      "27036  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...   vasc\n",
      "Labels\n",
      "vasc     4210\n",
      "akiec    4201\n",
      "nv       4196\n",
      "mel      4192\n",
      "df       4183\n",
      "bkl      4177\n",
      "bcc      4167\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data\n",
      "                                                  Images Labels\n",
      "3858   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...  akiec\n",
      "6253   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...    bcc\n",
      "27099  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...   vasc\n",
      "6498   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...    bcc\n",
      "16085  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...     df\n",
      "Labels\n",
      "bcc      132\n",
      "df       113\n",
      "bkl      113\n",
      "mel      111\n",
      "nv       104\n",
      "akiec    103\n",
      "vasc      96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Data\n",
      "                                                  Images Labels\n",
      "2789   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...  akiec\n",
      "19443  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...    mel\n",
      "2393   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...  akiec\n",
      "12387  C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...    bkl\n",
      "3745   C:/Users/Pratik/OneDrive/Desktop/pr_project/ba...  akiec\n",
      "Labels\n",
      "bkl      120\n",
      "df       114\n",
      "bcc      111\n",
      "nv       110\n",
      "mel      107\n",
      "akiec    106\n",
      "vasc     104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split from train_df (assuming train_df contains all your training data)\n",
    "X_train, X_dummies = train_test_split(\n",
    "    train_df, test_size=0.05, random_state=42)\n",
    "\n",
    "# Test/validation split from X_dummies\n",
    "X_test, X_val = train_test_split(X_dummies, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the splits information\n",
    "print(\"Training Data\")\n",
    "print(X_train.head())\n",
    "print(X_train['Labels'].value_counts())\n",
    "\n",
    "print(\"\\nTest Data\")\n",
    "print(X_test.head())\n",
    "print(X_test['Labels'].value_counts())\n",
    "\n",
    "print(\"\\nValidation Data\")\n",
    "print(X_val.head())\n",
    "print(X_val['Labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29326 validated image filenames belonging to 7 classes.\n",
      "Found 772 validated image filenames belonging to 7 classes.\n",
      "Found 772 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize ImageDataGenerator\n",
    "# Rescaling pixel values to [0, 1]\n",
    "image_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Train data generator\n",
    "train = image_gen.flow_from_dataframe(\n",
    "    dataframe=X_train,\n",
    "    x_col=\"Images\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(224, 224),  # Adjusted target_size\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=True  # Shuffle for training data\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test = image_gen.flow_from_dataframe(\n",
    "    dataframe=X_test,\n",
    "    x_col=\"Images\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(224, 224),  # Adjusted target_size\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False  # Shuffle off for testing data\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val = image_gen.flow_from_dataframe(\n",
    "    dataframe=X_val,\n",
    "    x_col=\"Images\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(224, 224),  # Adjusted target_size\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False  # Shuffle off for validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "Classes = list(train.class_indices.keys())\n",
    "print(Classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,124,655</span> (80.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,124,655\u001b[0m (80.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,175</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m263,175\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the input shape\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Load the Xception base model\n",
    "base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",\n",
    "                                            input_shape=img_shape, pooling='max')\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Construct the classification head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dropout(rate=0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(rate=0.25),\n",
    "    Dense(7, activation='softmax')  # 7 units for the 7 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adamax(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pratik\\OneDrive\\Desktop\\pr_project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1619s\u001b[0m 4s/step - accuracy: 0.4114 - loss: 1.5894 - val_accuracy: 0.5907 - val_loss: 1.0337\n",
      "Epoch 2/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2124s\u001b[0m 5s/step - accuracy: 0.5590 - loss: 1.1688 - val_accuracy: 0.6412 - val_loss: 0.9400\n",
      "Epoch 3/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 3s/step - accuracy: 0.5904 - loss: 1.0781 - val_accuracy: 0.6503 - val_loss: 0.9058\n",
      "Epoch 4/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1148s\u001b[0m 2s/step - accuracy: 0.6095 - loss: 1.0263 - val_accuracy: 0.6723 - val_loss: 0.8423\n",
      "Epoch 5/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1136s\u001b[0m 2s/step - accuracy: 0.6295 - loss: 0.9787 - val_accuracy: 0.6839 - val_loss: 0.8343\n",
      "Epoch 6/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1134s\u001b[0m 2s/step - accuracy: 0.6375 - loss: 0.9474 - val_accuracy: 0.6865 - val_loss: 0.7912\n",
      "Epoch 7/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1132s\u001b[0m 2s/step - accuracy: 0.6554 - loss: 0.9077 - val_accuracy: 0.7163 - val_loss: 0.7786\n",
      "Epoch 8/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1131s\u001b[0m 2s/step - accuracy: 0.6603 - loss: 0.8948 - val_accuracy: 0.7008 - val_loss: 0.7617\n",
      "Epoch 9/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1130s\u001b[0m 2s/step - accuracy: 0.6687 - loss: 0.8736 - val_accuracy: 0.7047 - val_loss: 0.7334\n",
      "Epoch 10/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1131s\u001b[0m 2s/step - accuracy: 0.6801 - loss: 0.8482 - val_accuracy: 0.7085 - val_loss: 0.7388\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=10, validation_data=val, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.7108 - loss: 0.7986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7869207262992859, 0.7020725607872009]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model in .keras format\n",
    "model.save('saved_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5680s\u001b[0m 12s/step - accuracy: 0.5921 - loss: 1.0859 - val_accuracy: 0.8899 - val_loss: 0.2844\n",
      "Epoch 2/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5678s\u001b[0m 12s/step - accuracy: 0.9187 - loss: 0.2390 - val_accuracy: 0.9262 - val_loss: 0.2084\n",
      "Epoch 3/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5655s\u001b[0m 12s/step - accuracy: 0.9695 - loss: 0.0892 - val_accuracy: 0.9430 - val_loss: 0.1885\n",
      "Epoch 4/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5665s\u001b[0m 12s/step - accuracy: 0.9844 - loss: 0.0473 - val_accuracy: 0.9534 - val_loss: 0.1925\n",
      "Epoch 5/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5612s\u001b[0m 12s/step - accuracy: 0.9897 - loss: 0.0336 - val_accuracy: 0.9482 - val_loss: 0.1934\n",
      "Epoch 6/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5585s\u001b[0m 12s/step - accuracy: 0.9891 - loss: 0.0311 - val_accuracy: 0.9275 - val_loss: 0.2848\n",
      "Epoch 7/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5588s\u001b[0m 12s/step - accuracy: 0.9916 - loss: 0.0267 - val_accuracy: 0.9521 - val_loss: 0.2389\n",
      "Epoch 8/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5590s\u001b[0m 12s/step - accuracy: 0.9926 - loss: 0.0205 - val_accuracy: 0.9365 - val_loss: 0.2578\n",
      "Epoch 9/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5595s\u001b[0m 12s/step - accuracy: 0.9873 - loss: 0.0401 - val_accuracy: 0.9715 - val_loss: 0.1584\n",
      "Epoch 10/10\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5502s\u001b[0m 12s/step - accuracy: 0.9952 - loss: 0.0140 - val_accuracy: 0.9521 - val_loss: 0.2601\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Load the saved model\n",
    "model = load_model('saved_model.keras')\n",
    "\n",
    "# Step 2: Unfreeze the last few layers of the base model (Xception)\n",
    "# Assuming the base_model is the first layer in the saved model\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze all layers from a specific layer forward, if needed (optional)\n",
    "# For example, to unfreeze only the top 20 layers of the base model:\n",
    "# for layer in base_model.layers[:-20]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Step 3: Re-compile the model with a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    # Use a smaller learning rate for fine-tuning\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 4: Continue training the model\n",
    "history = model.fit(train, epochs=10, validation_data=val, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'fine_tuned_model.keras'\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save('fine_tuned_model.keras')\n",
    "print(\"Model saved as 'fine_tuned_model.keras'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'fine_tuned_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save('fine_tuned_model.h5')\n",
    "print(\"Model saved as 'fine_tuned_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved using pickle and joblib.\n",
      "Loaded from pickle: {'classes': ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'], 'input_shape': (224, 224, 3), 'preprocessing': 'normalization'}\n",
      "Loaded from joblib: {'classes': ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'], 'input_shape': (224, 224, 3), 'preprocessing': 'normalization'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "import os\n",
    "\n",
    "# Example metadata to save (replace with actual metadata like class mappings)\n",
    "metadata = {\n",
    "    'classes': list(train.class_indices.keys()),  # Class names\n",
    "    'input_shape': (224, 224, 3),                # Model input shape\n",
    "    'preprocessing': 'normalization',            # Description of preprocessing\n",
    "}\n",
    "\n",
    "# Save metadata with pickle\n",
    "with open('model_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "# Save metadata with joblib\n",
    "dump(metadata, 'model_metadata.joblib')\n",
    "\n",
    "print(\"Metadata saved using pickle and joblib.\")\n",
    "\n",
    "# Load metadata back (if needed)\n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata_pkl = pickle.load(f)\n",
    "print(\"Loaded from pickle:\", metadata_pkl)\n",
    "\n",
    "metadata_joblib = load('model_metadata.joblib')\n",
    "print(\"Loaded from joblib:\", metadata_joblib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pipeline saved using pickle and joblib.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pratik\\OneDrive\\Desktop\\pr_project\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 160 variables whereas the saved optimizer has 318 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pipeline with pickle.\n",
      "Loaded pipeline with joblib.\n",
      "Pipeline Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,194,784</span> (160.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,194,784\u001b[0m (160.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,070,127</span> (80.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,070,127\u001b[0m (80.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,528</span> (213.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m54,528\u001b[0m (213.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,070,129</span> (80.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m21,070,129\u001b[0m (80.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "class ModelPipeline:\n",
    "    def __init__(self, model, metadata):\n",
    "        self.model = model\n",
    "        self.metadata = metadata\n",
    "\n",
    "\n",
    "# Wrap the trained model and metadata into a custom object\n",
    "pipeline = ModelPipeline(\n",
    "    model=model,\n",
    "    metadata={\n",
    "        'classes': list(train.class_indices.keys()),  # Class names\n",
    "        'input_shape': (224, 224, 3)                # Model input shape\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the pipeline with pickle\n",
    "with open('model_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "# Save the pipeline with joblib\n",
    "dump(pipeline, 'model_pipeline.joblib')\n",
    "print(\"Model pipeline saved using pickle and joblib.\")\n",
    "\n",
    "# Load the pipeline back\n",
    "with open('model_pipeline.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "print(\"Loaded pipeline with pickle.\")\n",
    "\n",
    "loaded_pipeline_joblib = load('model_pipeline.joblib')\n",
    "print(\"Loaded pipeline with joblib.\")\n",
    "\n",
    "# You can now access the model and metadata\n",
    "print(\"Pipeline Model Summary:\")\n",
    "loaded_pipeline.model.summary()\n",
    "print(\"Classes:\", loaded_pipeline.metadata['classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ac519dd43c9e5041c44214778d06bad78b52fac1b86643d697d31c2a3142346"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
